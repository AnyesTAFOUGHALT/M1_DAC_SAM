{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZzLUr_l_Wfb"
      },
      "source": [
        "# TP 1 et 2 : Accès aux données avec index\n",
        "# sujet\n",
        "\n",
        "date de modification : 18/01/2024\n",
        "\n",
        "BINOME\n",
        "\n",
        "NOM 1: TAFOUGHALT\n",
        "\n",
        "Prénom 1: Anyes\n",
        "\n",
        "NOM 2: DJEGHALI\n",
        "\n",
        "Prénom 2: Racha Nadine\n",
        "\n",
        "TP à rendre : **REDIGER des explications détaillées et argumentées** pour les solutions que vous proposez"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TJrAm4JFr9V"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "Objectifs:\n",
        "Savoir organiser des données en pages pour permettre de modifier un tuple en ne modifiant qu'une seule page.\n",
        "\n",
        "Comprendre les méthodes d'accès suivantes :\n",
        "\n",
        "*   Lecture séquentielle d'une fichier : \"table access full\"\n",
        "*   Lecture d'un tuple dont on connait le rowid : \"table access by index rowid\"\n",
        "*   Opération de sélection par lecture séquentielle et filtrage\n",
        "\n",
        "Comprendre les méthodes d'indexation :\n",
        "\n",
        "*   Créer un index\n",
        "*   Opération de sélection par index et lecture par rowid\n",
        "\n",
        "Mise à jour de données\n",
        "*   Sélectionner un tuple et modifier un de ses attributs\n",
        "*   Modifier l'index en conséquence lorsque l'attibut modifié est indexé\n",
        "\n",
        "Persistence\n",
        "*   Stocker un index (dans plusieurs pages) pour le reconstruire plus rapidement\n",
        "*   Adapter en conséquence les opérations de modification de l'index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aodlGU01gLqK",
        "outputId": "ac046998-c29b-44ae-a932-a57d7a0d90cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "le nom de la table est T\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil as sh\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# from sortedcontainers import SortedDict\n",
        "import sortedcontainers\n",
        "\n",
        "from string import ascii_lowercase\n",
        "import time\n",
        "\n",
        "# le nom de la table\n",
        "TABLE = \"T\"\n",
        "print(\"le nom de la table est\", TABLE)\n",
        "\n",
        "\n",
        "# le nom du fichier qui contient les données de la table\n",
        "def nom_fichier(table):\n",
        "    return table + \".csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRKX2fgx_gYT"
      },
      "source": [
        "# Générer les données du TP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezxoKUCxtASX"
      },
      "source": [
        "Création du fichier contenant un exemple de données.\n",
        "Ce sont des données au format csv. On suppose que chaque ligne correspond à un tuple d'une table **T** ayant *n* attributs :\n",
        "\n",
        "$$ T (a_0, a_1, a_2, ..., a_{n-1})$$\n",
        "\n",
        "Le premier attribut $a_0$ est unique.\n",
        "\n",
        "Les attributs $a_1$ à $a_{n-2}$ ne sont pas uniques : il y a en moyenne $2^k$ tuples par valeurs de $a_k$ soit 2 tuples par valeur de $a_1$ et 4 tuples par valeurs de $a_2$.\n",
        "\n",
        "Les attributs sont des nombres entiers, multiples de 10, sauf le dernier qui est une chaine de caractères (on choisit des mutliples de 10 pour représenter le cas plus général de domaines contenant des valeurs non consécutives).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "TIvmnhsTryK4"
      },
      "outputs": [],
      "source": [
        "# dure environ 20s pour 2M lignes\n",
        "# dure environ 40s pour 5M lignes\n",
        "\n",
        "\n",
        "def genere_fichier(nb_lignes, nb_attributs, longueur_dernier_attribut, table):\n",
        "  # attribut_chaine_caracteres = \"\".join(choice(ascii_lowercase) for i in range(longueur_dernier_attribut))\n",
        "  attribut_chaine_caracteres = ''.join('-' for i in range(longueur_dernier_attribut))\n",
        "  # print(\"le dernier attribut de chaque tuple est la chaine de caracètes :\", attribut_chaine_caracteres)\n",
        "\n",
        "  # reproductibilité des données générées\n",
        "  rng = np.random.default_rng(seed=1)\n",
        "\n",
        "  data={}\n",
        "\n",
        "  # le premier attribut est unique.\n",
        "  nb_valeurs_distinctes = nb_lignes\n",
        "  data['a0'] = 10 * rng.permutation(np.arange(nb_valeurs_distinctes))\n",
        "\n",
        "  # les attributs suivants ont des domaines plus petits :\n",
        "  for i in range(1, nb_attributs):\n",
        "    # on divise le domaine par 2 à chaque itération\n",
        "    nb_valeurs_distinctes = max(2, int(nb_valeurs_distinctes / 2))\n",
        "    data[f'a{i}'] = 10 * rng.integers(0, nb_valeurs_distinctes, nb_lignes)\n",
        "\n",
        "  # on concatène \"verticalement\" les attributs dans un dataframe pour former des tuples sur lesquels on peut itérer.\n",
        "  df = pd.DataFrame(data)\n",
        "  # rmq: le dernier attribut est une chaine de caractères\n",
        "  b = [str(e)[1:-1] + f\",{attribut_chaine_caracteres}\\n\" for e in df.itertuples(index=False, name=None)]\n",
        "\n",
        "\n",
        "\n",
        "  # on stocke les données dans un fichier\n",
        "  fichier = nom_fichier(table)\n",
        "  print(\"écriture des données dans le fichier\", fichier)\n",
        "  with open(fichier, \"w\") as f:\n",
        "    # écriture groupée de tous les tuples\n",
        "    f.write(''.join(b))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNu_7pJg62jv",
        "outputId": "b546d6d6-93aa-42ed-b9e1-95eefaceb96e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "écriture des données dans le fichier T.csv\n",
            "durée pour générer 2000000 lignes : 14.7 s\n"
          ]
        }
      ],
      "source": [
        "nb_lignes = 2 * 1000 * 1000\n",
        "# nb_lignes = 5 * 1000 * 1000\n",
        "nb_attributs = 7\n",
        "longueur_dernier_attribut = 100\n",
        "\n",
        "t1 = time.time()\n",
        "genere_fichier(nb_lignes, nb_attributs, longueur_dernier_attribut, TABLE)\n",
        "print(f\"durée pour générer {nb_lignes} lignes :\", round(time.time() - t1, 1), \"s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogkKxanaBHQF"
      },
      "source": [
        "On affiche le début et la fin du fichier et son nombre de lignes ( = card(T))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aMC3Y6yryK-",
        "outputId": "1d0d6cb9-8952-4976-9fe5-d2666a059600"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "debut de T.csv :\n",
            "19512870, 5751570, 1235270, 1344040, 1139220, 359300, 261790,----------------------------------------------------------------------------------------------------\n",
            "3462320, 3047440, 4558650, 2392580, 332870, 445910, 35390,----------------------------------------------------------------------------------------------------\n",
            "\n",
            "fin de T.csv : \n",
            "4418430, 9611540, 268500, 660850, 881140, 311230, 273070,----------------------------------------------------------------------------------------------------\n",
            "1896950, 9749280, 4493840, 1757100, 1083240, 323240, 177530,----------------------------------------------------------------------------------------------------\n",
            "\n",
            "nombre de lignes:\n",
            "2000000 T.csv\n"
          ]
        }
      ],
      "source": [
        "%%bash -s \"{TABLE}.csv\"\n",
        "echo \"debut de $1 :\"\n",
        "head -n 2 $1\n",
        "echo\n",
        "echo \"fin de $1 : \"\n",
        "tail -n 2 $1\n",
        "echo\n",
        "echo \"nombre de lignes:\"\n",
        "wc -l $1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gm8_3CY_odp"
      },
      "source": [
        "# Lecture séquentielle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZaYoqeiHO2p"
      },
      "source": [
        "On définit un *iterateur* pour lire séquentiellement chaque ligne de la table stockée entièrement dans un seul fichier.\n",
        "Le mot python *yield* permet de définir un itérateur qui est retourné par la fonction.\n",
        "\n",
        "Cet itérateur est invoqué pour lire la table et appliquer un filtre.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSX2XxLx_tBa",
        "outputId": "9127e0d2-ed44-46a8-d82b-7324f891f894"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valeur recherchée : 963852\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "durée : 2.713 s\n"
          ]
        }
      ],
      "source": [
        "def lecture_sequentielle(table):\n",
        "  fichier = nom_fichier(table)\n",
        "  with open(fichier, \"r\") as f:\n",
        "    for i, line in enumerate(f):\n",
        "      yield i, line\n",
        "\n",
        "def filtrer_table(table, valeur_recherchee):\n",
        "  for i, line in lecture_sequentielle(table):\n",
        "      a = int(line.split(',')[0])\n",
        "      if a == valeur_recherchee :\n",
        "        print(f\"ligne {i} :\", line.strip())\n",
        "\n",
        "\n",
        "nb_valeurs_distinctes = nb_lignes\n",
        "s = np.random.randint(nb_valeurs_distinctes)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "filtrer_table(TABLE, s)\n",
        "print(\"durée :\", round(time.time() - t1, 3), \"s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlmFE3aZTBWC"
      },
      "source": [
        "# Découper une table en pages\n",
        "\n",
        "On organise les données en pages.\n",
        "Pour faciliter le TP, chaque page est représentée par un \"petit\" fichier mais en réalité une page est un bloc d'un fichier.\n",
        "\n",
        "Dans la suite du TP, on accédera toujours aux pages.\n",
        "Le fichier créé initialement, contenant tous les tuples, ne sera plus utilisé."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOEddKG8PHDF",
        "outputId": "90e5e4dd-7471-4c7f-f38a-8c50f4b0dc8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "les pages sont stockées dans le dossier T_pages\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nb pages créées : 2000\n"
          ]
        }
      ],
      "source": [
        "def page_dir_name(table):\n",
        "  return table + \"_pages\"\n",
        "\n",
        "def decoupe_table_en_pages(table, nb_tuple_par_page):\n",
        "  page_dir = page_dir_name(table)\n",
        "\n",
        "  # vider le dossier qui contiendra les pages\n",
        "  if(os.path.exists(page_dir)):\n",
        "    sh.rmtree(page_dir)\n",
        "  os.makedirs(page_dir, exist_ok=True)\n",
        "\n",
        "  # lire le fichier contenant tous les tuples\n",
        "  p=0\n",
        "  lines = []\n",
        "  for i, line in lecture_sequentielle(table):\n",
        "    lines.append(line)\n",
        "    if (i+1) % nb_tuple_par_page == 0:\n",
        "\n",
        "      # créer une page\n",
        "      p += 1\n",
        "      with open(page_dir + f\"/page{p}\", \"w\") as fp:\n",
        "        fp.write(''.join(lines))\n",
        "      lines = []\n",
        "\n",
        "  # créer une dernière page, si nécessaire\n",
        "  if len(lines) > 0:\n",
        "    p +=1\n",
        "    with open(page_dir + f\"/page{p}\", \"w\") as fp:\n",
        "        fp.write(''.join(lines))\n",
        "\n",
        "  print(\"nb pages créées :\", p)\n",
        "\n",
        "\n",
        "print(\"les pages sont stockées dans le dossier\", page_dir_name(TABLE) )\n",
        "\n",
        "decoupe_table_en_pages(TABLE, nb_tuple_par_page=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqaml72_bXkj"
      },
      "source": [
        "Afficher (pour quelques pages) le nombre de tuples contenus dans une page"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMqMNrHbbWof"
      },
      "source": [
        "une solution en bash :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEX48QWEClJD",
        "outputId": "37670eeb-c5bc-4fc8-a53d-7e1abeb9784d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     1000 T_pages/page1\n",
            "     1000 T_pages/page10\n",
            "     1000 T_pages/page100\n"
          ]
        }
      ],
      "source": [
        "%%bash -s \"$TABLE\"\n",
        "wc -l $1_pages/* | head -n 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3OlZo1ZbToW"
      },
      "source": [
        "une autre solution en python :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99NDkIXsXKrf",
        "outputId": "48fec9f7-69e6-47e2-aa7c-672f42a3cd7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "la page page1402 contient 1000 lignes\n",
            "la page page854 contient 1000 lignes\n",
            "la page page1522 contient 1000 lignes\n"
          ]
        }
      ],
      "source": [
        "page_dir = page_dir_name(TABLE)\n",
        "l = os.listdir(page_dir)\n",
        "random.seed(1)\n",
        "for i in range(3):\n",
        "  une_page = random.choice(l)\n",
        "  with open(page_dir + f\"/{une_page}\", 'r') as fp:\n",
        "    lines = len(fp.readlines())\n",
        "    print(f\"la page {une_page} contient {lines} lignes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4XDZAmbcUQb"
      },
      "source": [
        "# Lecture séquentielle d'une table découpée en pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPVOrVpKccUG",
        "outputId": "f4d6f86b-df4e-4d2f-9260-f4bd0c358cc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valeur recherchée : 1613801\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "durée : 4.99 s\n"
          ]
        }
      ],
      "source": [
        "def lecture_sequentielle_par_page(table):\n",
        "  page_dir = page_dir_name(table)\n",
        "  nb_pages = len(os.listdir(page_dir))\n",
        "  for p in range(1, nb_pages+1) :\n",
        "    with open(page_dir + f\"/page{p}\", \"r\") as f:\n",
        "      for i, line in enumerate(f):\n",
        "        tuple_courant = line.strip().split(',')\n",
        "        yield p, i, tuple_courant\n",
        "\n",
        "def filtrer_table_par_pages(table, valeur_recherchee):\n",
        "  for page, position, tuple_courant in lecture_sequentielle_par_page(table):\n",
        "    attribut0 = int(tuple_courant[0])\n",
        "    if attribut0 == valeur_recherchee :\n",
        "      print(f\"page {page}, ligne {position} :\", tuple_courant)\n",
        "\n",
        "search = np.random.randint(nb_lignes)\n",
        "print(\"valeur recherchée :\", search)\n",
        "\n",
        "t1 = time.time()\n",
        "filtrer_table_par_pages(TABLE, search)\n",
        "print(\"durée :\", round(time.time() - t1, 2), \"s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcmdLaQ5ruBJ"
      },
      "source": [
        "# Lecture d'un tuple dans une page"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow_RkbQ_U8qs"
      },
      "source": [
        "Cette fonction retourne le tuple situé dans la page *num_page* et à la position *position*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4tYi4xCrxFG",
        "outputId": "862f6029-b6ee-4f07-8fef-c7a967d2c752",
        "tags": [
          "parameters"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17233030, 9546020, 4178470, 117430, 31540, 530090, 250650,----------------------------------------------------------------------------------------------------\n",
            "done in 1.7 ms\n"
          ]
        }
      ],
      "source": [
        "def lecture_tuple(table, num_page, position):\n",
        "  page_dir = page_dir_name(table)\n",
        "  with open(page_dir + f\"/page{num_page}\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    return lines[position].strip()\n",
        "\n",
        "t1 = time.time()\n",
        "print(lecture_tuple(TABLE, 123, 456))\n",
        "print(\"done in\", round((time.time() - t1)*1000, 1), \"ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mD_xZjLxXLD"
      },
      "source": [
        "# Exercice 1 : Créer un index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNgxRQtOTwOH"
      },
      "source": [
        "## Créer un index unique pour l'attribut $a_0$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCJyftyiXyFo"
      },
      "source": [
        "On sait que $a_0$ est unique.\n",
        "Une entrée de l'index associe une *clé* à une *valeur* :\n",
        "*   La *clé* est la valeur du premier attribut.\n",
        "*   La *valeur* est un **rowid** formé des informations (page, position)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fhy4IJ0bxWHD",
        "outputId": "a7351bb7-e172-439c-d65c-8b0aa36c09c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "durée  10.178 s\n"
          ]
        }
      ],
      "source": [
        "def creation_index_unique(table):\n",
        "  index = {}\n",
        "  for page, position, tuple_courant in lecture_sequentielle_par_page(table):\n",
        "    attribut0 = int(tuple_courant[0])\n",
        "    index[attribut0] = (page,position)\n",
        "  return sortedcontainers.SortedDict(index)\n",
        "\n",
        "t1 = time.time()\n",
        "INDEX_UNIQUE_a0 = creation_index_unique(TABLE)\n",
        "print(\"durée \", round(time.time() - t1, 3), \"s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WbJm39uuwgn",
        "outputId": "03c079ec-f91f-427c-f687-c3fc781b230b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9538850 (499, 702)\n"
          ]
        }
      ],
      "source": [
        "# vérifier l'index\n",
        "s = 10 * np.random.randint(nb_lignes)\n",
        "print(s, INDEX_UNIQUE_a0[s])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcUQ8XRcT1dg"
      },
      "source": [
        "## Créer un index non unique pour l'attribut $a_i$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4AtpJouWSmB"
      },
      "source": [
        "On donne un nom de table et le numéro $i$ de l'attribut $a_i$ de la table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxJC1-m-VRC5",
        "outputId": "9c4984af-93f6-462b-aee3-5e219c0a5a73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "duree de création de l'index pour l'attribut a2: 12.631 s\n"
          ]
        }
      ],
      "source": [
        "def creation_index(table, numero_attribut):\n",
        "  index = {}\n",
        "  for page, position, tuple_courant in lecture_sequentielle_par_page(table):\n",
        "    attribut_val = int(tuple_courant[numero_attribut])\n",
        "    if(attribut_val not in index):\n",
        "      index[attribut_val]=[(page,position)]\n",
        "    else:\n",
        "      index[attribut_val].append((page,position))\n",
        "  return sortedcontainers.SortedDict(index)\n",
        "\n",
        "\n",
        "t1 = time.time()\n",
        "INDEX_a2 = creation_index(TABLE, 2)\n",
        "print(\"duree de création de l'index pour l'attribut a2:\", round(time.time() - t1, 3), \"s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INubLbmNttNJ",
        "outputId": "341b79ea-9986-40ee-bdb8-3b6a9c0b6be0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valeur recherchée : 4176740\n",
            "(240, 847)\n",
            "(547, 483)\n",
            "(1078, 662)\n",
            "(1209, 500)\n",
            "(1821, 498)\n"
          ]
        }
      ],
      "source": [
        "# # vérifier l'index\n",
        "s = 10 * np.random.randint(nb_valeurs_distinctes/4)\n",
        "print(\"valeur recherchée :\", s)\n",
        "for r in INDEX_a2[s]:\n",
        "  print(r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qA7hCef5Kfa"
      },
      "source": [
        "# Exerccie 2 : Accès par index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0zrHPfGJjzm"
      },
      "source": [
        "## Accès ciblé\n",
        "\n",
        "On veut retrouver les tuples telq qu'un attribut indexé a une valeur donnée."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEEUaCYqhIaB"
      },
      "source": [
        "###Index unique scan.\n",
        "On recherche un unique tuple dont l'attribut indexé a une valeur donnée (car l'attribut est unique)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH3f5bz-5JTu",
        "outputId": "e209e4f8-3591-47da-ec5e-4e255d71c0ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valeur recherchée : 9224270\n",
            "resulat: 9224270, 8819320, 2908210, 171370, 882390, 263060, 223710,----------------------------------------------------------------------------------------------------\n",
            "done in 2.61 ms\n"
          ]
        }
      ],
      "source": [
        "def acces_par_index_unique(index_unique, table, valeur_recherchee):\n",
        " num_page, position =  index_unique[valeur_recherchee]\n",
        " return lecture_tuple(table, num_page, position)\n",
        "\n",
        "s = 10 * np.random.randint(nb_lignes)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "tuple = acces_par_index_unique(INDEX_UNIQUE_a0, TABLE, s)\n",
        "print(\"resulat:\", tuple)\n",
        "print(\"done in\", round((time.time() - t1)*1000, 2), \"ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfR_0QAShCJi"
      },
      "source": [
        "###Index scan\n",
        "Accès pour rechercher les tuples dont l'attribut indexé a une valeur donnée. On suppose que l'attribut n'est pas unique et que plusieurs tuples sont retrouvés"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eyjynk_hZer",
        "outputId": "c0a38acc-8692-40d5-ea57-e2e64ba0f63a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valeur recherchée : 1344280\n",
            "43670, 2944140, 1344280, 2414210, 256370, 618290, 190770,----------------------------------------------------------------------------------------------------\n",
            "17961130, 5800270, 1344280, 430700, 766790, 129870, 123260,----------------------------------------------------------------------------------------------------\n",
            "18071160, 1507990, 1344280, 2218530, 587740, 173650, 16140,----------------------------------------------------------------------------------------------------\n",
            "14560010, 6120300, 1344280, 363450, 891020, 469650, 240210,----------------------------------------------------------------------------------------------------\n",
            "done in 7.04 ms\n"
          ]
        }
      ],
      "source": [
        "def acces_par_index(index, table, valeur_recherchee):\n",
        "\n",
        "    tuples_indices=  index[valeur_recherchee]\n",
        "    tuples = []\n",
        "    for page , position  in tuples_indices :\n",
        "       tuples.append(lecture_tuple(table, page, position))\n",
        "    return tuples\n",
        "\n",
        "\n",
        "\n",
        "s = 10* np.random.randint(nb_lignes/4)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "for t in acces_par_index(INDEX_a2, TABLE, s):\n",
        "  print(t)\n",
        "print(\"done in\", round((time.time() - t1)*1000, 2), \"ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afvN2LWhJs0V"
      },
      "source": [
        "## Accès par intervalle\n",
        "Index range scan\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIL6jrUuaPMO"
      },
      "source": [
        "### Accès par intervalle sur un attribut unique\n",
        "Accès pour rechercher les tuples dont l'attribut indexé est unique et a une valeur comprise dans un intervalle donné.\n",
        "Indications, votre solution doit prendre en compte les exigences suivantes :\n",
        "*  Les valeurs recherchées ne sont pas connues à l'avance. On sait seulement qu'elles sont incluses dans un intervalle. Ne pas supposer qu'on recherche des entiers consécutifs.\n",
        "*  Les bornes de l'intervalle ne sont pas parmi les valeurs existantes de l'attribut. Par exemple, on peut rechercher les valeurs de $a_0$ comprises dans l'intervalle  [23 , 45].\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8maKd3mdqxKU",
        "outputId": "d754247d-56cb-4e79-8474-0e20f3f9f090"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "l'indice de la première clé à retrouver est : 3\n",
            "la première clé retrouvée est: 30\n",
            "la valeur à retrouver est : (1783, 941)\n"
          ]
        }
      ],
      "source": [
        "# Exemple pour retrouver la première entrée de l'intervalle [23,45]\n",
        "\n",
        "indice = INDEX_UNIQUE_a0.bisect_left(23)\n",
        "print(\"l'indice de la première clé à retrouver est :\", indice)\n",
        "cle = INDEX_UNIQUE_a0.keys()[indice]\n",
        "print(\"la première clé retrouvée est:\", cle)\n",
        "print(\"la valeur à retrouver est :\",  INDEX_UNIQUE_a0[cle])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGEO1PheSEdT",
        "outputId": "58d6ee6d-d983-414f-85bb-ea41646c6175"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valeurs recherchées seront dans l'intervalle : [ 4721033 , 4721053 ]\n",
            "4721040, 6932710, 1952880, 2312330, 612760, 491600, 97530,----------------------------------------------------------------------------------------------------\n",
            "4721050, 8586970, 3578540, 1810690, 493410, 431490, 255740,----------------------------------------------------------------------------------------------------\n",
            "done in 0.01 s\n"
          ]
        }
      ],
      "source": [
        "def acces_intervalle_par_index_unique(index_unique, table, borne_inf, borne_sup):\n",
        "    indice_inf = index_unique.bisect_left(borne_inf)\n",
        "    i = indice_inf\n",
        "    tuples = []\n",
        "    cle = index_unique.keys()[i]\n",
        "    while( cle <=  borne_sup ):\n",
        "      tuples.append(acces_par_index_unique(index_unique, table, cle))\n",
        "      i += 1\n",
        "      cle = index_unique.keys()[i]\n",
        "\n",
        "    return tuples\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "s = 10 * np.random.randint(nb_valeurs_distinctes/4)\n",
        "print(\"valeurs recherchées seront dans l'intervalle : [\", s+3 , \",\",s+23,\"]\")\n",
        "\n",
        "t1 = time.time()\n",
        "for t in acces_intervalle_par_index_unique(INDEX_UNIQUE_a0, TABLE, s + 3, s + 23):\n",
        "  print(t)\n",
        "print(\"done in\", round(time.time() - t1, 2), \"s\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDaG7WelaQrG"
      },
      "source": [
        "### Accès par intervalle sur un attribut NON unique\n",
        "Accès pour rechercher les tuples dont l'attribut indexé n'est **pas** unique et a une valeur comprise dans un intervalle donné.\n",
        "Votre solution doit prendre en compte les mêmes exigences que dans la question précédente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQEYfcoEak5A",
        "outputId": "4c7b891d-5a93-43fe-e987-0dea448d145c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valeurs recherchées seront dans l'intervalle : [ 2513263 , 2513293 ]\n",
            "923330, 1155930, 2513270, 2486250, 603540, 587060, 65960,----------------------------------------------------------------------------------------------------\n",
            "18295370, 5980220, 2513270, 633160, 1198720, 425810, 140600,----------------------------------------------------------------------------------------------------\n",
            "11891130, 8744070, 2513270, 1578560, 716620, 221950, 267190,----------------------------------------------------------------------------------------------------\n",
            "51570, 8081260, 2513270, 1448800, 898140, 118680, 13240,----------------------------------------------------------------------------------------------------\n",
            "12240670, 5827940, 2513280, 1093360, 438580, 396170, 296770,----------------------------------------------------------------------------------------------------\n",
            "5813610, 4234760, 2513280, 2347770, 124240, 141400, 151000,----------------------------------------------------------------------------------------------------\n",
            "11498500, 7183050, 2513280, 1199240, 778350, 420970, 302520,----------------------------------------------------------------------------------------------------\n",
            "6528440, 2413020, 2513280, 1580630, 961520, 473490, 159350,----------------------------------------------------------------------------------------------------\n",
            "4619170, 718110, 2513280, 40040, 292100, 67050, 145970,----------------------------------------------------------------------------------------------------\n",
            "16841440, 1293980, 2513280, 5010, 434120, 348340, 88070,----------------------------------------------------------------------------------------------------\n",
            "11649910, 8105900, 2513280, 1448640, 303410, 48390, 61130,----------------------------------------------------------------------------------------------------\n",
            "17514800, 3097760, 2513280, 1322640, 895290, 419540, 74830,----------------------------------------------------------------------------------------------------\n",
            "17808440, 8820670, 2513290, 1824840, 20520, 551580, 254210,----------------------------------------------------------------------------------------------------\n",
            "18060360, 8573540, 2513290, 504190, 204430, 557800, 209140,----------------------------------------------------------------------------------------------------\n",
            "16738180, 7695740, 2513290, 1703670, 369620, 290650, 233220,----------------------------------------------------------------------------------------------------\n",
            "1961750, 2368600, 2513290, 372580, 528930, 479760, 103380,----------------------------------------------------------------------------------------------------\n",
            "done in 0.02 s\n"
          ]
        }
      ],
      "source": [
        "def acces_intervalle_par_index(index, table, borne_inf, borne_sup):\n",
        "    indice_inf = index.bisect_left(borne_inf)\n",
        "    i = indice_inf\n",
        "    tuples = []\n",
        "    cle = index.keys()[i]\n",
        "    while( cle <=  borne_sup ):\n",
        "      tuples.extend(acces_par_index(index, table, cle))\n",
        "      i += 1\n",
        "      cle = index.keys()[i]\n",
        "\n",
        "    return tuples\n",
        "\n",
        "s = 10 * np.random.randint(nb_valeurs_distinctes / 4)\n",
        "print(\"valeurs recherchées seront dans l'intervalle : [\", s+3 , \",\",s+33,\"]\")\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "for t in acces_intervalle_par_index(INDEX_a2, TABLE, s + 3, s + 33):\n",
        "  print(t)\n",
        "print(\"done in\", round(time.time() - t1, 2), \"s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Rjm99DrKR8t"
      },
      "source": [
        "# Exercice 3 : Mise à jour de données\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7np5NI8OKK6z"
      },
      "source": [
        "## Modifier la valeur d'un attribut d'un ou plusieurs tuples\n",
        "\n",
        "Cela correspond à l'insctruction UPDATE table SET ... WHERE ...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7aN87BOuEbq"
      },
      "source": [
        "### Modification d'un seul tuple\n",
        "\n",
        "On donne une valeur *v* de l'attribut clé $a_0$. Ajouter 10 à l'attribut $a_1$. Cela correspond à l'instruction\n",
        "\n",
        "update T\n",
        "set a1 = a1+10\n",
        "where a0 = *v*\n",
        "\n",
        "Après la modification, accéder aux données pour vérifier que le tuple a bien été modifié. Par exemple, invoquer la fonction\n",
        "acces_par_index_unique(index, table, v)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ecriture_tuple(table, num_page, position,valeur_a_additionner,indince_a_modifier):\n",
        "    page_dir = page_dir_name(table)\n",
        "    with open(page_dir + f\"/page{num_page}\", \"r+\") as f:\n",
        "        lines = f.readlines()\n",
        "        a0 = int(lines[position].strip().split(',')[indince_a_modifier])\n",
        "        print(\"Valeur initiale : \",a0)\n",
        "        a0 += valeur_a_additionner\n",
        "        print(\"Valeur apres modification : \",a0)\n",
        "        l = lines[position]\n",
        "        l = l.strip().split(',')\n",
        "        l[indince_a_modifier] = \" \"+str(a0)\n",
        "        lines[position] =','.join(l)+\"\\n\"\n",
        "        f.seek(0)\n",
        "        f.writelines(lines)\n",
        "\n",
        "def update_unique(index, table, v):\n",
        "    num_page , position = index[v]\n",
        "    ecriture_tuple(table,num_page,position,10,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "avant la mise à jour  18709620, 5479280, 4390800, 2477770, 941380, 286730, 209680,----------------------------------------------------------------------------------------------------\n",
            "Valeur initiale :  5479280\n",
            "Valeur apres modification :  5479290\n",
            "aprés la mise à jour  18709620, 5479290, 4390800, 2477770, 941380, 286730, 209680,----------------------------------------------------------------------------------------------------\n",
            "done in 0.01 s\n"
          ]
        }
      ],
      "source": [
        "# Test :\n",
        "v = 18709620\n",
        "print(\"avant la mise à jour \" , acces_par_index_unique(INDEX_UNIQUE_a0,TABLE,v))\n",
        "t1 = time.time()\n",
        "update_unique(INDEX_UNIQUE_a0, TABLE, v)\n",
        "t2 = round(time.time() - t1, 2)\n",
        "print(\"aprés la mise à jour \", acces_par_index_unique(INDEX_UNIQUE_a0,TABLE,v))\n",
        "print(\"done in\", t2, \"s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdexpmRuKfs2"
      },
      "source": [
        "### Modification de plusieurs tuples\n",
        "\n",
        "On donne une valeur *v* de l'attribut $a_2$ qui n'est pas unique. Ajouter 1 à l'attribut $a_3$ de tous les tuples pour lesquels $a_2 = v$\n",
        "\n",
        "update T set a3 = a3+1 where a2=v\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_plusieurs(index, table, v):\n",
        "    tuples_indices=  index[v]\n",
        "    dict_page_pos = {}\n",
        "    for page , position  in tuples_indices :\n",
        "        if(page in dict_page_pos):\n",
        "            dict_page_pos[page].append(position)\n",
        "        else :\n",
        "            dict_page_pos[page] = [position]\n",
        "    for num_page in list(dict_page_pos.keys()):\n",
        "        page_dir = page_dir_name(table)\n",
        "        with open(page_dir + f\"/page{num_page}\", \"r+\") as f:\n",
        "            lines = f.readlines()\n",
        "            for position in dict_page_pos[num_page] :\n",
        "                print(\"page : \",num_page,\", position : \",position)\n",
        "                a3 = int(lines[position].strip().split(',')[3])\n",
        "                print(\"Valeur initiale : \",a3)\n",
        "                a3 += 10\n",
        "                print(\"Valeur apres modification : \",a3)\n",
        "                l = lines[position]\n",
        "                l = l.strip().split(',')\n",
        "                l[3] = \" \"+str(a3)\n",
        "                lines[position] =','.join(l)+\"\\n\"\n",
        "            f.seek(0)\n",
        "            f.writelines(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "avant la mise à jour  ['3907520, 9680, 321940, 298970, 436620, 418330, 191630,----------------------------------------------------------------------------------------------------', '1471360, 2647260, 321940, 1628930, 1247700, 587260, 186440,----------------------------------------------------------------------------------------------------', '14074930, 4504850, 321940, 817210, 747080, 268220, 142460,----------------------------------------------------------------------------------------------------', '7460450, 6149070, 321940, 813120, 1193110, 332950, 71640,----------------------------------------------------------------------------------------------------']\n",
            "page :  854 , position :  869\n",
            "Valeur initiale :  298970\n",
            "Valeur apres modification :  298980\n",
            "page :  973 , position :  359\n",
            "Valeur initiale :  1628930\n",
            "Valeur apres modification :  1628940\n",
            "page :  1525 , position :  82\n",
            "Valeur initiale :  817210\n",
            "Valeur apres modification :  817220\n",
            "page :  1866 , position :  364\n",
            "Valeur initiale :  813120\n",
            "Valeur apres modification :  813130\n",
            "aprés la mise à jour  ['3907520, 9680, 321940, 298980, 436620, 418330, 191630,----------------------------------------------------------------------------------------------------', '1471360, 2647260, 321940, 1628940, 1247700, 587260, 186440,----------------------------------------------------------------------------------------------------', '14074930, 4504850, 321940, 817220, 747080, 268220, 142460,----------------------------------------------------------------------------------------------------', '7460450, 6149070, 321940, 813130, 1193110, 332950, 71640,----------------------------------------------------------------------------------------------------']\n",
            "\n",
            "Done in 0.01 s\n"
          ]
        }
      ],
      "source": [
        "v = 321940\n",
        "print(\"avant la mise à jour \", acces_par_index(INDEX_a2,TABLE,v) )\n",
        "t1 = time.time()\n",
        "update_plusieurs(INDEX_a2, TABLE, v)\n",
        "t2 = round(time.time() - t1, 2)\n",
        "print(\"aprés la mise à jour \" , acces_par_index(INDEX_a2,TABLE,v))\n",
        "print(\"\\nDone in\", t2, \"s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zAZws5_KaL8"
      },
      "source": [
        "##Modifier l'index en conséquence lorsque l'attribut modifié est indexé\n",
        "Comerncer par créer un index sur l'attribut $a_3$\n",
        "\n",
        "L'attribut $a_3$ étant maintenant indexé, la mise à jour de la question précédente implique d'actualiser l'index sur $a_3$ pour que les rowid des tuples qui contenaient l'ancienne valeur de $a_3$ soient associés à la nouvelle valeur de $a_3$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_plusieurs_2(index2, index3, table, v):\n",
        "    tuples_indices=  index2[v]\n",
        "    dict_page_pos = {}\n",
        "    for page , position  in tuples_indices :\n",
        "        if(page in dict_page_pos):\n",
        "            dict_page_pos[page].append(position)\n",
        "        else :\n",
        "            dict_page_pos[page] = [position]\n",
        "    for num_page in list(dict_page_pos.keys()):\n",
        "        page_dir = page_dir_name(table)\n",
        "        with open(page_dir + f\"/page{num_page}\", \"r+\") as f:\n",
        "            lines = f.readlines()\n",
        "            for position in dict_page_pos[num_page] :\n",
        "                print(\"page : \",num_page,\", position : \",position)\n",
        "                a3 = int(lines[position].strip().split(',')[3])\n",
        "                index3[a3].remove((num_page,position))\n",
        "                print(\"Valeur initiale : \",a3)\n",
        "                a3 += 10\n",
        "                print(\"Valeur apres modification : \",a3)\n",
        "                l = lines[position]\n",
        "                l = l.strip().split(',')\n",
        "                l[3] = \" \"+str(a3)\n",
        "                if(a3 not in index3):\n",
        "                    index3[a3]=[(num_page,position)]\n",
        "                else:\n",
        "                     index3[a3].append((num_page,position))\n",
        "                lines[position] =','.join(l)+\"\\n\"\n",
        "            f.seek(0)\n",
        "            f.writelines(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "duree de création de l'index pour l'attribut a3: 10.568 s\n"
          ]
        }
      ],
      "source": [
        "# Creation d'un index pour l'atribut a3 :\n",
        "t1 = time.time()\n",
        "INDEX_a3 = creation_index(TABLE, 3)\n",
        "print(\"duree de création de l'index pour l'attribut a3:\", round(time.time() - t1, 3), \"s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "avant la mise à jour  ['10379420, 9830890, 3468200, 2393910, 454100, 231470, 116810,----------------------------------------------------------------------------------------------------', '8695360, 4248230, 3468200, 1700890, 103740, 207030, 72370,----------------------------------------------------------------------------------------------------']\n",
            "page :  2 , position :  0\n",
            "Valeur initiale :  2393910\n",
            "Valeur apres modification :  2393920\n",
            "page :  49 , position :  485\n",
            "Valeur initiale :  1700890\n",
            "Valeur apres modification :  1700900\n",
            "aprés la mise à jour  ['10379420, 9830890, 3468200, 2393920, 454100, 231470, 116810,----------------------------------------------------------------------------------------------------', '8695360, 4248230, 3468200, 1700900, 103740, 207030, 72370,----------------------------------------------------------------------------------------------------']\n",
            "\n",
            "Done in 0.01 s\n"
          ]
        }
      ],
      "source": [
        "#test :\n",
        "v = 3468200\n",
        "print(\"avant la mise à jour \", acces_par_index(INDEX_a2,TABLE,v) )\n",
        "t1 = time.time()\n",
        "update_plusieurs_2(INDEX_a2,INDEX_a3, TABLE, v)\n",
        "t2 = round(time.time() - t1, 2)\n",
        "print(\"aprés la mise à jour \" , acces_par_index(INDEX_a2,TABLE,v))\n",
        "print(\"\\nDone in\", t2, \"s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as_W7xmOKc3l"
      },
      "source": [
        "# Exercice 4 : Persistence\n",
        "\n",
        "Dans cette partie, on veut rendre les index persistents en stockant les entrées triées dans des pages. Cela permet d'utiliser les index plus efficacement en réduisant la durée pour les reconstruire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy8NE3x5KgLj"
      },
      "source": [
        "## Stockage d'un index unique\n",
        "\n",
        "Proposez une solution pour stocker les entrées **triées** d'un index dans plusieurs pages avec une taille de page fixée (10 000 rowids par page).\n",
        "Etudier le cas d'un index unique et celui d'un index non unique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "VqSClCOgKl6a"
      },
      "outputs": [],
      "source": [
        "def index_unique_dir_name(table):\n",
        "  return table + \"_index_unique\"\n",
        "def index_unique(index , table , nb_index_par_page=10000):\n",
        "    dir = index_unique_dir_name(table)\n",
        "\n",
        "    if(os.path.exists(dir)):\n",
        "        sh.rmtree(dir)\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "    index_keys = sorted(index.keys())\n",
        "    p=0\n",
        "    lines = []\n",
        "    for i,key in enumerate(index_keys):\n",
        "       lines.append(str(key)+\",\"+str(index[key][0])+\",\"+str(index[key][1])+\"\\n\")\n",
        "       if (i+1) % nb_index_par_page == 0:\n",
        "            # créer une page\n",
        "            p += 1\n",
        "            with open( dir + f\"/page{p}\", \"w\") as fp:\n",
        "                fp.write(''.join(lines))\n",
        "            lines = []\n",
        "    # créer une dernière page, si nécessaire\n",
        "    if len(lines) > 0:\n",
        "        p +=1\n",
        "        with open(dir + f\"/page{p}\", \"w\") as fp:\n",
        "            fp.write(''.join(lines))\n",
        "    print(\"nb pages créées :\", p)\n",
        "\n",
        "\n",
        "       \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nb pages créées : 200\n",
            "\n",
            "Done in 8.64 s\n"
          ]
        }
      ],
      "source": [
        "#test\n",
        "t1 = time.time()\n",
        "index_unique(INDEX_UNIQUE_a0 , TABLE )\n",
        "t2 = round(time.time() - t1, 2)\n",
        "print(\"\\nDone in\", t2, \"s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "def index_non_unique_dir_name(table,att):\n",
        "  return table + \"_index_non_unique_a\"+str(att)\n",
        "def index_non_unique(index , att, table , nb_index_par_page=10000):\n",
        "    dir = index_non_unique_dir_name(table, att)\n",
        "\n",
        "    if(os.path.exists(dir)):\n",
        "        sh.rmtree(dir)\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "    index_keys = sorted(index.keys())\n",
        "    p=0\n",
        "    lines = []\n",
        "    for key in index_keys:\n",
        "        if len(lines) + len(index[key]) > nb_index_par_page :\n",
        "            p += 1\n",
        "            with open( dir + f\"/page{p}\", \"w\") as fp:\n",
        "                fp.write(''.join(lines))\n",
        "            lines = []\n",
        "        for num_page, position in index[key]:\n",
        "            lines.append(str(key)+\",\"+str(num_page)+\",\"+str(position)+\"\\n\")\n",
        "    # créer une dernière page, si nécessaire\n",
        "    if len(lines) > 0 :\n",
        "        p +=1\n",
        "        with open(dir + f\"/page{p}\", \"w\") as fp:\n",
        "            fp.write(''.join(lines))\n",
        "    print(\"nb pages créées :\", p)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "duree de création de l'index pour l'attribut a1: 15.081 s\n",
            "nb pages créées : 201\n",
            "\n",
            "Done in 6.1 s\n"
          ]
        }
      ],
      "source": [
        "#test\n",
        "\n",
        "t1 = time.time()\n",
        "INDEX_a1 = creation_index(TABLE, 1)\n",
        "print(\"duree de création de l'index pour l'attribut a1:\", round(time.time() - t1, 3), \"s\")\n",
        "t1 = time.time()\n",
        "index_non_unique(INDEX_a1 , 1, TABLE )\n",
        "t2 = round(time.time() - t1, 2)\n",
        "print(\"\\nDone in\", t2, \"s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nb pages créées : 201\n",
            "\n",
            "Done in 4.81 s\n"
          ]
        }
      ],
      "source": [
        "#test\n",
        "t1 = time.time()\n",
        "index_non_unique(INDEX_a2 , 2, TABLE )\n",
        "t2 = round(time.time() - t1, 2)\n",
        "print(\"\\nDone in\", t2, \"s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nb pages créées : 201\n",
            "\n",
            "Done in 4.92 s\n"
          ]
        }
      ],
      "source": [
        "#test\n",
        "t1 = time.time()\n",
        "index_non_unique(INDEX_a3 , 3, TABLE )\n",
        "t2 = round(time.time() - t1, 2)\n",
        "print(\"\\nDone in\", t2, \"s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EblJsOaluV7"
      },
      "source": [
        "Montrez que vous pouvez reconstruire les index à partir des entrées stockées dans des pages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "LxCiuoRRl1IL"
      },
      "outputs": [],
      "source": [
        "#Reconstruire l'index unique\n",
        "def reconstruction_index (index_dir):\n",
        "  index = {}\n",
        "  nb_pages = len(os.listdir(index_dir))\n",
        "  for page in range(1,nb_pages+1):\n",
        "    with open(index_dir +f\"/page{page}\", \"r\") as f:\n",
        "      line = f.readline()\n",
        "      cle , _ , _ = line.strip().split(',')\n",
        "      if int(cle) not in index : \n",
        "        index[int(cle)] = page\n",
        "\n",
        "  return sortedcontainers.SortedDict(index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "index_unique_non_dense = reconstruction_index (\"T_index_unique\")\n",
        "index_a2_non_dense = reconstruction_index (\"T_index_non_unique_a2\")\n",
        "index_a1_non_dense = reconstruction_index (\"T_index_non_unique_a1\")\n",
        "index_a3_non_dense= reconstruction_index (\"T_index_non_unique_a3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzDPXcGzKjKU"
      },
      "source": [
        "## Adapter en conséquence les opérations de modification de l'index\n",
        "\n",
        "Illustrer le cas :\n",
        "\n",
        "update T set a3 = a3+0.5 where a1=v\n",
        "\n",
        "où la nouvelle valeur $a_3' = a_3 + 0.5$ n'est pas déjà présente dans l'index. Il faut donc insérer une nouvelle clé  dans l'index de l'attribut $a_3$.\n",
        "On suppose qu'il reste de la place dans une page de l'index pour insérer la nouvelle entrée (on peut avoir jusqu'à 12 000 rowids par page d'index)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "y9mXqJeFKmUE"
      },
      "outputs": [],
      "source": [
        "\n",
        "def update_table_index(table, index , num_att , value_att , new_value_att , num_page , position) :\n",
        "    index_dir = index_non_unique_dir_name(table, num_att)    \n",
        "    i = index.bisect_left(value_att)\n",
        "    cle = index.keys()[i]\n",
        "    page = index[cle]\n",
        "    if cle != value_att :\n",
        "        page -=1 \n",
        "\n",
        "    #suppression de l'ancienne entrée d'index \n",
        "    with open(index_dir + f\"/page{page}\", \"r+\") as f:\n",
        "        lines = f.readlines()\n",
        "        for i , line in enumerate(lines):\n",
        "            cle , num_page2 , position2 = line.strip().split(',')\n",
        "            if int(cle) == value_att and num_page2==num_page and position2==position:\n",
        "                lines.remove(i)\n",
        "                break\n",
        "        f.seek(0)\n",
        "        f.writelines(''.join(lines))  \n",
        "\n",
        "    #insertion de la nouvelle entrée d'index\n",
        "    i = index.bisect_left(new_value_att)\n",
        "    cle = index.keys()[i]\n",
        "    page = index[cle] - 1\n",
        "    with open(index_dir + f\"/page{page}\", \"r+\") as f:\n",
        "        lines = f.readlines()\n",
        "        new_lines = []\n",
        "        for i , line in enumerate(lines):\n",
        "            cle , num_page2 , position2 = line.strip().split(',')\n",
        "            if int(cle) > new_value_att :\n",
        "                if i!=0 :\n",
        "                    new_lines = lines[:i]\n",
        "                new_lines.append(str(new_value_att)+\",\"+str(num_page)+\",\"+str(position)+\"\\n\")\n",
        "                new_lines.extend(lines[i:])\n",
        "                break\n",
        "        if len(new_lines)==0:\n",
        "            new_lines=lines\n",
        "            new_lines.append(str(new_value_att)+\",\"+str(num_page)+\",\"+str(position)+\"\\n\")\n",
        "        f.seek(0)\n",
        "        f.writelines(''.join(new_lines))  \n",
        "   \n",
        "        \n",
        "def modification_bis(index1, index_non_dense_a3, table, v):\n",
        "    #je pense qu'ici on doit utiliser l'index non dense de a1 (c'est ce qu'on fait dans cette partie)\n",
        "\n",
        "    index_dir = index_non_unique_dir_name(table, 1)    \n",
        "    i = index1.bisect_left(v)\n",
        "    cle = index1.keys()[i]\n",
        "    page = index1[cle]\n",
        "    if cle != v :\n",
        "        page -=1 \n",
        "\n",
        "    #ON récupere tous les rowids des tuples à modifier qui ont la val de l'attribut a1 = v\n",
        "    dict_page_pos= {}\n",
        "    cle_retrouvee = False\n",
        "    with open(index_dir + f\"/page{page}\", \"r+\") as f:\n",
        "        lines = f.readlines()\n",
        "        for i , line in enumerate(lines):\n",
        "            cle , num_page2 , position2 = line.strip().split(',')\n",
        "            if int(cle) == v :\n",
        "                if(int(num_page2) in dict_page_pos):\n",
        "                    dict_page_pos[int(num_page2)].append(int(position2))\n",
        "                else :\n",
        "                    dict_page_pos[int(num_page2)]=[int(position2)]\n",
        "                cle_retrouvee = True\n",
        "            elif cle_retrouvee :\n",
        "                break\n",
        "\n",
        "    \n",
        "    page_dir = page_dir_name(table)\n",
        "    for num_page in dict_page_pos.keys() :\n",
        "        with open(page_dir + f\"/page{num_page}\", \"r+\") as f:\n",
        "            lines = f.readlines()\n",
        "            for position in dict_page_pos[num_page] :\n",
        "                a3 = int(lines[position].strip().split(',')[3])\n",
        "                print(\"Valuer initiale : \",a3)\n",
        "                update_table_index(table , index_non_dense_a3 , 3 , a3 , a3 + 0.5 , num_page , position) \n",
        "                a3 += 0.5\n",
        "                print(\"Valuer apres modification : \",a3)\n",
        "                l = lines[position]\n",
        "                l = l.strip().split(',')\n",
        "                l[3] = \" \"+str(a3)\n",
        "                lines[position] =','.join(l)+\"\\n\"\n",
        "            f.seek(0)\n",
        "            f.writelines(''.join(lines))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "avant la mise à jour  ['5424120, 7765780, 1292450, 1362210, 330190, 401730, 206430,----------------------------------------------------------------------------------------------------', '12563170, 7765780, 3791110, 1353460, 512600, 261000, 305670,----------------------------------------------------------------------------------------------------', '6375430, 7765780, 3043010, 1797280, 637490, 539070, 252720,----------------------------------------------------------------------------------------------------']\n",
            "Valuer initiale :  1362210\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valuer apres modification :  1362210.5\n",
            "Valuer initiale :  1353460\n",
            "Valuer apres modification :  1353460.5\n",
            "Valuer initiale :  1797280\n",
            "Valuer apres modification :  1797280.5\n",
            "aprés la mise à jour  ['5424120, 7765780, 1292450, 1362210.5, 330190, 401730, 206430,----------------------------------------------------------------------------------------------------', '12563170, 7765780, 3791110, 1353460.5, 512600, 261000, 305670,----------------------------------------------------------------------------------------------------', '6375430, 7765780, 3043010, 1797280.5, 637490, 539070, 252720,----------------------------------------------------------------------------------------------------']\n",
            "\n",
            "Done in 1.3 s\n"
          ]
        }
      ],
      "source": [
        "#test :\n",
        "v = 7765780\n",
        "print(\"avant la mise à jour \", acces_par_index(INDEX_a1,TABLE,v) )\n",
        "t1 = time.time()\n",
        "modification_bis(index_a1_non_dense, index_a3_non_dense, TABLE, v)\n",
        "t2 = round(time.time() - t1, 2)\n",
        "print(\"aprés la mise à jour \" , acces_par_index(INDEX_a1,TABLE,v) )\n",
        "print(\"\\nDone in\", t2, \"s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUTS_HFziuGv"
      },
      "source": [
        "# Exercice 5 : Index bitmap\n",
        "*   Proposer un index ayant une structure matricielle (\"bitmap\") pour l'attribut $a_5$. Idem pour l'attribut $a_6$.\n",
        "*   En utilisant les 2 index bitmap, rechercher les tuples de T tels que $a_5 = v_1$ et $a_6 = v_2$ pour deux valeurs $v_1, v_2$ appartenant au domaine de $a_5 \\cap a_6$ .\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eiRWHoci4l2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQDDXVCZi022"
      },
      "source": [
        "\n",
        "## Facultatif: Index couvrant une requête\n",
        "* Illustrer les cas vus en TD pour lesquels il est possible d'obtenir le résultat d'une requête sans lire les données de la table lais seulement les index.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n600I2Vii5FO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
